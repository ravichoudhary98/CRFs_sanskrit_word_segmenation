{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CbvP4i96fmZx",
    "outputId": "128b7a8f-1763-41c3-85d9-a7d7afe11646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-crfsuite in /usr/local/lib/python3.6/dist-packages (0.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCFjtk-Vepvx"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, HTTPError\n",
    "import pycrfsuite\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/ravichoudhary98/CRFs_sanskrit_word_segmenation/raw/master/data/'\n",
    "file_name = 'output_train_sent1.txt'\n",
    "base_url = url + file_name\n",
    "urllib.request.urlretrieve(base_url, file_name)\n",
    "\n",
    "#sentences list for sanskrit data\n",
    "with open('output_train_sent1.txt') as f:\n",
    "    sentences = f.readlines()\n",
    "# you may also remove whitespace characters like `\\n` at the end of each line\n",
    "sentences = [x.strip() for x in sentences] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U5Xvoo8fbhCc",
    "outputId": "49d444c4-48cb-4a75-cf9c-1cd171f3800c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102712"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVg_v6iEepw9"
   },
   "outputs": [],
   "source": [
    "sentences = [s for s in sentences if len(s) > 5] # remove very short \"sentences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "StGjAbkTepxF",
    "outputId": "32a99389-fe69-4458-cfd4-4b8fd6e13e76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁यस्य ▁साड्य ▁अ Bआव् अः ▁प्रमाRअ ▁अन्तर् एRअ ▁निScइत ः ▁स ▁बाड् इतः\n"
     ]
    }
   ],
   "source": [
    "print(sentences[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCDcgrlTepxQ"
   },
   "source": [
    "For preparing our training data, every sentence is converted into a char list together with the information wether the char marks the beginning of a new word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4SxUIRvVepxS",
    "outputId": "bd06d654-2822-4102-ffec-f72a1fedd2f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▁', 0), ('द', 0), ('े', 0), ('व', 0), ('ा', 0), ('ग', 1), ('ा', 0), ('र', 0), ('्', 0), ('अ', 1), ('स', 0), ('्', 0), ('य', 0), ('▁', 1), ('ख़', 0), ('न', 1), ('्', 0), ('अ', 1), ('न', 0), ('म', 0), ('्', 0), ('▁', 1), ('न', 0), ('ि', 0), ('ड', 0), ('ा', 0), ('न', 0), ('▁', 1), ('ख़', 0), ('न', 1), ('्', 0), ('अ', 1), ('न', 0), ('म', 0), ('्', 0), ('▁', 1), ('त', 0), ('ट', 0), ('ा', 0)]\n"
     ]
    }
   ],
   "source": [
    "prepared_sentences = list()\n",
    "\n",
    "for sentence in sentences:\n",
    "    lengths = [len(w) for w in sentence.split(\" \")]\n",
    "    positions = []\n",
    "\n",
    "    next_pos = 0\n",
    "    for length in lengths:\n",
    "        next_pos = next_pos + length\n",
    "        positions.append(next_pos)\n",
    "    concatenated = sentence.replace(\" \", \"\")\n",
    "\n",
    "    chars = [c for c in concatenated]\n",
    "    labels = [0 if not i in positions else 1 for i, c in enumerate(concatenated)]\n",
    "\n",
    "    prepared_sentences.append(list(zip(chars, labels)))\n",
    "    \n",
    "    \n",
    "print([d for d in prepared_sentences[21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT43pOMkepxa"
   },
   "source": [
    "## Transforming the characters to feature vectors.\n",
    "\n",
    "Finally, we can create some simple n-gram features. Obviously, you could think of much more sophisticated features and possibly improve our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tP7y0t20epxc"
   },
   "outputs": [],
   "source": [
    "def create_char_features(sentence, i):\n",
    "    features = [\n",
    "        'bias',\n",
    "        'char=' + sentence[i][0] \n",
    "    ]\n",
    "    \n",
    "    if i >= 1:\n",
    "        features.extend([\n",
    "            'char-1=' + sentence[i-1][0],\n",
    "            'char-1:0=' + sentence[i-1][0] + sentence[i][0],\n",
    "        ])\n",
    "    else:\n",
    "        features.append(\"BOS\")\n",
    "        \n",
    "    if i >= 2:\n",
    "        features.extend([\n",
    "            'char-2=' + sentence[i-2][0],\n",
    "            'char-2:0=' + sentence[i-2][0] + sentence[i-1][0] + sentence[i][0],\n",
    "            'char-2:-1=' + sentence[i-2][0] + sentence[i-1][0],\n",
    "        ])\n",
    "        \n",
    "    if i >= 3:\n",
    "        features.extend([\n",
    "            'char-3:0=' + sentence[i-3][0] + sentence[i-2][0] + sentence[i-1][0] + sentence[i][0],\n",
    "            'char-3:-1=' + sentence[i-3][0] + sentence[i-2][0] + sentence[i-1][0],\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    if i + 1 < len(sentence):\n",
    "        features.extend([\n",
    "            'char+1=' + sentence[i+1][0],\n",
    "            'char:+1=' + sentence[i][0] + sentence[i+1][0],\n",
    "        ])\n",
    "    else:\n",
    "        features.append(\"EOS\")\n",
    "        \n",
    "    if i + 2 < len(sentence):\n",
    "        features.extend([\n",
    "            'char+2=' + sentence[i+2][0],\n",
    "            'char:+2=' + sentence[i][0] + sentence[i+1][0] + sentence[i+2][0],\n",
    "            'char+1:+2=' + sentence[i+1][0] + sentence[i+2][0],\n",
    "        ])\n",
    "        \n",
    "    if i + 3 < len(sentence):\n",
    "        features.extend([\n",
    "            'char:+3=' + sentence[i][0] + sentence[i+1][0] + sentence[i+2][0]+ sentence[i+3][0],\n",
    "            'char+1:+3=' + sentence[i+1][0] + sentence[i+2][0] + sentence[i+3][0],\n",
    "        ])\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def create_sentence_features(prepared_sentence):\n",
    "    return [create_char_features(prepared_sentence, i) for i in range(len(prepared_sentence))]\n",
    "\n",
    "def create_sentence_labels(prepared_sentence):\n",
    "    return [str(part[1]) for part in prepared_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4dFokuNepxk"
   },
   "outputs": [],
   "source": [
    "X = [create_sentence_features(ps) for ps in prepared_sentences[:-30000]]\n",
    "y = [create_sentence_labels(ps)   for ps in prepared_sentences[:-30000]]\n",
    "\n",
    "X_test = [create_sentence_features(ps) for ps in prepared_sentences[-30000:]]\n",
    "y_test = [create_sentence_labels(ps)   for ps in prepared_sentences[-30000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q5fPvoHCgOks",
    "outputId": "859af3af-59ae-4919-d68c-33bc2b68f093"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71957, 71957, 30000, 30000)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(y),len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKlGmRuKepxv"
   },
   "source": [
    "## Training a CRF\n",
    "Now, we use Python-CRFSuite for training a CRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNNHd_Tcepxw"
   },
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X, y):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDSxJsSnepx4"
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0, \n",
    "    'c2': 1e-3,\n",
    "    'max_iterations': 60,\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yd3OT-lVlkrs",
    "outputId": "2ea22290-9cec-414c-940d-6f38c3079714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pycrfsuite._pycrfsuite.Trainer"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CuYY-yXHepyD"
   },
   "outputs": [],
   "source": [
    "trainer.train('sanskrit-text-segmentation.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ugxkG6-6epyM",
    "outputId": "6e29fc99-9484-47d2-aad2-7633d00b0838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f684ff4a898>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('sanskrit-text-segmentation.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "coJj6TcLepyU"
   },
   "outputs": [],
   "source": [
    "def segment_sentence(sentence):\n",
    "    sent = sentence.replace(\" \", \"\")\n",
    "    prediction = tagger.tag(create_sentence_features(sent))\n",
    "    complete = \"\"\n",
    "    for i, p in enumerate(prediction):\n",
    "        if p == \"1\":\n",
    "            complete += \" \" + sent[i]\n",
    "        else:\n",
    "            complete += sent[i]\n",
    "    return complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VP4V3tRtlCtK"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/ravichoudhary98/CRFs_sanskrit_word_segmenation/raw/master/data/'\n",
    "file_name = 'input.txt'\n",
    "base_url = url + file_name\n",
    "urllib.request.urlretrieve(base_url, file_name)\n",
    "\n",
    "#use this if you want to convert all text file into segmented text \n",
    "outF = open(\"output.txt\", \"w\")\n",
    "\n",
    "with open('input.txt','r') as f:\n",
    "    for line in f:\n",
    "        l1 = \"\"\n",
    "        l2 = \"\"\n",
    "        if len(line)<=10:\n",
    "            l1=line\n",
    "            #outF.write(line)\n",
    "            outF.write(l1)\n",
    "        else:\n",
    "            seg = segment_sentence(line)\n",
    "            l2 = seg\n",
    "            outF.write(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HyLwb1xNKmW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_cTqtbC_zQr4",
    "outputId": "92054757-6d95-4e4a-9dd6-b51a2e748871"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6283"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_fwf('output.txt', header=None)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hIDxqzI2epyb",
    "outputId": "6acd5a73-a7bc-463b-b7d2-de48d3e36d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "त्रि पञ् चाशदधिकैकशतं\n",
      "एक दिवसीय क्रि के ट स्पर्धा मालिका यां\n"
     ]
    }
   ],
   "source": [
    "print(segment_sentence(\"त्रिपञ्चाशदधिकैकशतं\"))\n",
    "print(segment_sentence(\"एकदिवसीयक्रिकेटस्पर्धामालिकायां\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unBY01SWepyj"
   },
   "source": [
    "Finally, let's find out how well our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDlTNwBRepyl"
   },
   "outputs": [],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "n_correct = 0\n",
    "n_incorrect = 0\n",
    "\n",
    "for s in prepared_sentences[-30000:]:\n",
    "    prediction = tagger.tag(create_sentence_features(s))\n",
    "    correct = create_sentence_labels(s)\n",
    "    zipped = list(zip(prediction, correct))\n",
    "    tp +=        len([_ for l, c in zipped if l == c and l == \"1\"])\n",
    "    fp +=        len([_ for l, c in zipped if l == \"1\" and c == \"0\"])\n",
    "    fn +=        len([_ for l, c in zipped if l == \"0\" and c == \"1\"])\n",
    "    n_incorrect += len([_ for l, c in zipped if l != c])\n",
    "    n_correct   += len([_ for l, c in zipped if l == c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "CAEqPLi5epys",
    "outputId": "877af737-8911-4028-9125-33f195cb4acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\t0.979928550540218\n",
      "Recall:\t\t0.9284058871761847\n",
      "Accuracy:\t0.9815456482318868\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\\t\" + str(tp/(tp+fp)))\n",
    "print(\"Recall:\\t\\t\" + str(tp/(tp+fn)))\n",
    "print(\"Accuracy:\\t\" + str(n_correct/(n_correct+n_incorrect)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CRFs-latin-word-segmenation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
